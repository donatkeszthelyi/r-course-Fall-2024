---
title: 'Assignment 2: Data visualization'
author: "Don√°t Keszthelyi"
date: 27/11/2024
output: html_document
editor_options: 
  chunk_output_type: console
---

You will have to create 3 plots based on the datasets and instructions detailed below. You will find the plots themeselves in the `assignments/assignment_2_plots`. Your task is to write the code that will reproduce the plots as closely as possible.

# Skills needed to solve this assignment

-   Using R and RStudio, reading data
-   Reporting using RMarkdown
-   Using Git and Github (for submitting the task)
-   Data manipulation (e.g. dplyr, tidyr), and working with factors (forcats)
-   Data visuzlization (ggplot2)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytuesdayR)
library(scales)
```

## Task 1: Climbing expeditions

The 2020-09-22 TidyTueday datasets are about climbing expeditions. From the three datasets, use the "expeditions". Reproduce the plot below! Notice a few things:

-   Use `forcats::fct_lump()` to get the 15 most frequent peaks, and drop the "Other" category.
-   The bars are ordered by the sum of all expeditions (use `fct_reorder()`).
-   The bar colors use the viridis palette and light theme.

```{r}
#Reading the data
expeditions_data <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/master/data/2020/2020-09-22/expeditions.csv")

#Selecting the most frequent peaks and dropping the rest
top_peaks <- expeditions_data |>
  count(peak_name, season) |>
  mutate(peak_name = fct_lump(peak_name, n = 15, w = n)) |>
  filter(peak_name != "Other") |>
  mutate(peak_name = fct_drop(peak_name))

#Ordering the top peaks by total expeditions (regardless of season)
top_peaks <- top_peaks |>
  group_by(peak_name) |>
  mutate(total_expeditions = sum(n)) |>
  ungroup() |>
  mutate(peak_name = fct_reorder(peak_name, total_expeditions, .desc = FALSE))

#Plotting the data
ggplot(top_peaks, aes(x = peak_name, y = n, fill = season)) +
  geom_bar(stat = "identity", position = "stack", show.legend = TRUE) +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(
    title = "The 15 most popular peaks stacked by season of expedition",
    x = NULL,
    y = "Number of expeditions"
  ) +
  theme_light() +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal"
  )
```

## Task 2: PhDs awarded

The 2019-02-19 TidyTueday dataset is about phd-s awarded by year and field. There is only one dataset, it is called `phd_by_field`. Reproduce the plot below!

Notes:

-   First you have to aggregate the data to count all phd-s by broad fields.
-   To make the x axis breaks pretty, use `scales::pretty_breaks()`, to make the y axis labels comma formatted, use `scales::comma_format()`.
-   The line size is 1.2, the colors are from the brewer "Dark2" palette. The theme is set to minimal.

```{r}
#Reading the data
phd_data <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/master/data/2019/2019-02-19/phd_by_field.csv")

#Aggregating the data (number of phds) by broad field and year
phd_by_field <- phd_data |>
  group_by(broad_field, year) |>
  summarise(total_phds = sum(n_phds, na.rm = TRUE), .groups = "drop")

#Plotting the data
ggplot(phd_by_field, aes(x = year, y = total_phds, color = broad_field, group = broad_field)) +
  geom_line(size = 1.2) +
  scale_color_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = pretty_breaks(n = 5)) +
  scale_y_continuous(labels = comma_format()) +
  labs(title = "Number of awarded Ph.D.-s in the US by year", 
       x = NULL, 
       y = NULL,
       color = "Broad field") +
  theme_minimal() +
  theme(legend.position = "right",
        panel.grid.major.x = element_line(size = 1),
        panel.grid.major.y = element_line(size = 1),)
```

## Task 3: Commute in the US

The 2019-11-05 TidyTueday dataset is about commuting to work in each city in the US by bike or on foot. There is only one dataset, it is called `commute`. Reproduce the plot below!

Notes:

-   First you have to aggregate the data to count all commutes by state.
-   Both axis scales are log transformed and the labels comma formatted, using `scales::comma_format()`
-   The point size is 2, . The theme is set to light.

```{r}
#Read the data
commute_data <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/master/data/2019/2019-11-05/commute.csv")

#Transform the data for plotting to a new dataframe
commute_by_state <- commute_data |>
  group_by(state_abb, state_region) |>
  summarise(
    walk = sum(n[mode == "Walk"], na.rm = TRUE),
    bike = sum(n[mode == "Bike"], na.rm = TRUE)
  ) |>
  ungroup()

#Plotting the data
ggplot(commute_by_state, aes(x = walk, y = bike, color = state_region, group = state_region)) +
  geom_point(size = 2) +
  scale_x_continuous(labels = comma_format(), trans = "log10") +
  scale_y_continuous(labels = comma_format(), trans = "log10", limits = c(20, NA)) +
  geom_text(aes(label = state_abb), color = "black", check_overlap = TRUE) +
  labs(title = "Title number of people walking vs. biking to work in each USA state", 
       x = "Number of ppl walking to work (log N)", 
       y = "Number of ppl biking to work (log N)",
       color = "State region") +
  theme_light()
```
